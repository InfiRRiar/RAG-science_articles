{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a3a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e75166fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115f51f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "e5_model = BertModel.from_pretrained(\"intfloat/e5-large-v2\", torch_dtype=\"auto\", device_map=\"auto\").to(device)\n",
    "e5_tokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-large-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3fdb34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1592\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "\n",
    "passages = pd.read_csv(\"../../ml/data/cleaned.csv\")[:10].abstract.tolist()\n",
    "passages = [\"passage: \" + passage for passage in passages]\n",
    "\n",
    "queries = pd.read_csv(\"test_data.csv\")\n",
    "queries, answer_ids = queries[\"question\"].tolist(), queries[\"relatable_abstract_id\"].tolist()\n",
    "queries = [\"query: \" + query for query in queries]\n",
    "\n",
    "# Each input text should start with \"query: \" or \"passage: \".\n",
    "# For tasks other than retrieval, you can simply use the \"query: \" prefix.\n",
    "input_texts = queries + passages\n",
    "\n",
    "print(max(map(len, input_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b43b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input texts\n",
    "batch_dict = e5_tokenizer(input_texts, max_length=1600, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "\n",
    "outputs = e5_model(**batch_dict)\n",
    "embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "# normalize embeddings\n",
    "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "scores = (embeddings[:len(queries)] @ embeddings[len(queries):].T).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "621f4f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = []\n",
    "for row in range(len(scores)):\n",
    "    rank = 1\n",
    "    current = scores[row][answer_ids[row]]\n",
    "    for x in scores[row]:\n",
    "        if x > current:\n",
    "            rank += 1\n",
    "    ranks.append(rank)\n",
    "\n",
    "ranks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-articles-GkDBBu19-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
